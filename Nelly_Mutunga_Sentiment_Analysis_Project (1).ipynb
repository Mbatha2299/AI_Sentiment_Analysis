{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **AMAZON PRODUCTS SENTIMENTAL ANALYSIS**\n",
    "\n",
    "#### **PROBLEM STATEMENT**\n",
    "With the introduction of e-commerce and wide usage of social media platforms, there is a lot of user-generated data ranging from current affairs, topical issues, and even product reviews. Companies and organizations are slowly taking cognizance of the impact of social media comments on their brands. They are now using sentiment analysis to monitor their brand reputation across social media platforms and the web in general.\n",
    "\n",
    "This projects uses a dataset from the Amazon webpage, https://www.tensorflow.org/datasets/catalog/amazon_us_reviews#amazon_us_reviewswireless_v1_00_default_config, to create three models that predict the sentiment of a review.\n",
    "\n",
    "#### **DEFINING THE METRIC FOR SUCCESS** \n",
    "The metric for success for this project is creating three models: Naive Bayes, Support Vector Machine and Logistic Reggression, with an accuracy of 80%, precision of 85% and recall of 80%.\n",
    "\n",
    "### **EXPERIMENTAL DESIGN**\n",
    "Loading libraries\n",
    "\n",
    "Loading data\n",
    "\n",
    "Reading data\n",
    "\n",
    "Cleaning data\n",
    "\n",
    "Feature Eng and Preprocessing\n",
    "\n",
    "Modeling\n",
    "\n",
    "Optimization and model evaluation\n",
    "\n",
    "Conclusions and recommedations\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import tweepy\n",
    "import warnings\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Scrapping Twitter using Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set up authentication credentials\n",
    "#consumer_key = 'xxxx'\n",
    "#consumer_secret = 'xxxx'\n",
    "#access_token = 'xxxx'\n",
    "#access_token_secret = 'xxxxxx'\n",
    "\n",
    "# Authenticate to Twitter\n",
    "#auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "#auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "\n",
    "# Create API object\n",
    "#api = tweepy.API(auth)\n",
    "\n",
    "# Specify the search query and number of tweets to fetch\n",
    "#query = \"Amazon\"\n",
    "#num_tweets = 1500\n",
    "\n",
    "# Fetch tweets containing the specified search query\n",
    "#tweets = api.search_tweets(q=query, lang=\"en\", tweet_mode=\"extended\", count=num_tweets)\n",
    "\n",
    "# Extract relevant information, such as tweet text and user information\n",
    "#for tweet in tweets:\n",
    "    #tweet_text = tweet.full_text\n",
    "    #user_info = tweet.user.screen_name\n",
    "    #print(f'Tweet: {tweet_text}')\n",
    "    #print(f'User: {user_info}')\n",
    "    #print('---')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading an existing Amazon review dataset from Tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec={'data': {'customer_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'helpful_votes': TensorSpec(shape=(), dtype=tf.int32, name=None), 'marketplace': TensorSpec(shape=(), dtype=tf.string, name=None), 'product_category': TensorSpec(shape=(), dtype=tf.string, name=None), 'product_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'product_parent': TensorSpec(shape=(), dtype=tf.string, name=None), 'product_title': TensorSpec(shape=(), dtype=tf.string, name=None), 'review_body': TensorSpec(shape=(), dtype=tf.string, name=None), 'review_date': TensorSpec(shape=(), dtype=tf.string, name=None), 'review_headline': TensorSpec(shape=(), dtype=tf.string, name=None), 'review_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'star_rating': TensorSpec(shape=(), dtype=tf.int32, name=None), 'total_votes': TensorSpec(shape=(), dtype=tf.int32, name=None), 'verified_purchase': TensorSpec(shape=(), dtype=tf.int64, name=None), 'vine': TensorSpec(shape=(), dtype=tf.int64, name=None)}}>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "ds = tfds.load('amazon_us_reviews/Mobile_Electronics_v1_00', split='train', shuffle_files=True)\n",
    "assert isinstance(ds, tf.data.Dataset)\n",
    "print(ds)\n",
    "#convert the dataset into a pandas dataframe\n",
    "df = tfds.as_dataframe(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data/customer_id</th>\n",
       "      <th>data/helpful_votes</th>\n",
       "      <th>data/marketplace</th>\n",
       "      <th>data/product_category</th>\n",
       "      <th>data/product_id</th>\n",
       "      <th>data/product_parent</th>\n",
       "      <th>data/product_title</th>\n",
       "      <th>data/review_body</th>\n",
       "      <th>data/review_date</th>\n",
       "      <th>data/review_headline</th>\n",
       "      <th>data/review_id</th>\n",
       "      <th>data/star_rating</th>\n",
       "      <th>data/total_votes</th>\n",
       "      <th>data/verified_purchase</th>\n",
       "      <th>data/vine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'20980074'</td>\n",
       "      <td>0</td>\n",
       "      <td>b'US'</td>\n",
       "      <td>b'Mobile_Electronics'</td>\n",
       "      <td>b'B00D1847NE'</td>\n",
       "      <td>b'274617424'</td>\n",
       "      <td>b'Teenage Mutant Ninja Turtles Boombox CD Play...</td>\n",
       "      <td>b'Does not work'</td>\n",
       "      <td>b'2015-01-09'</td>\n",
       "      <td>b'One Star'</td>\n",
       "      <td>b'R1OVS0D6SEXPW7'</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'779273'</td>\n",
       "      <td>0</td>\n",
       "      <td>b'US'</td>\n",
       "      <td>b'Mobile_Electronics'</td>\n",
       "      <td>b'B00KMO6DYG'</td>\n",
       "      <td>b'397452138'</td>\n",
       "      <td>b'4 Gauge Amp Kit Amplifier Install Wiring Com...</td>\n",
       "      <td>b'This is a great wiring kit i used it to set ...</td>\n",
       "      <td>b'2015-08-06'</td>\n",
       "      <td>b'Great kit'</td>\n",
       "      <td>b'R9VSD0ET8FERB'</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'15410531'</td>\n",
       "      <td>0</td>\n",
       "      <td>b'US'</td>\n",
       "      <td>b'Mobile_Electronics'</td>\n",
       "      <td>b'B000GWLL0K'</td>\n",
       "      <td>b'948304826'</td>\n",
       "      <td>b'Travel Wall Charger fits Creative Zen Vision...</td>\n",
       "      <td>b'It works great so much faster than USB charg...</td>\n",
       "      <td>b'2007-03-15'</td>\n",
       "      <td>b'A/C Charger for Creative Zen Vision M'</td>\n",
       "      <td>b'R3ISXCZHWLJLBH'</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'27389005'</td>\n",
       "      <td>0</td>\n",
       "      <td>b'US'</td>\n",
       "      <td>b'Mobile_Electronics'</td>\n",
       "      <td>b'B008L3JE6Y'</td>\n",
       "      <td>b'466340015'</td>\n",
       "      <td>b'High Grade Robust 360\\xc2\\xb0 Adjustable Car...</td>\n",
       "      <td>b'This product was purchased to hold a monitor...</td>\n",
       "      <td>b'2013-07-30'</td>\n",
       "      <td>b'camera stand'</td>\n",
       "      <td>b'R1TWVUDOFJSQAW'</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'2663569'</td>\n",
       "      <td>0</td>\n",
       "      <td>b'US'</td>\n",
       "      <td>b'Mobile_Electronics'</td>\n",
       "      <td>b'B00GHZS4SC'</td>\n",
       "      <td>b'350592810'</td>\n",
       "      <td>b'HDE Multifunctional Bluetooth FM Audio Car K...</td>\n",
       "      <td>b\"it works but it has really bad sound quality...</td>\n",
       "      <td>b'2014-12-31'</td>\n",
       "      <td>b'bad sound quality'</td>\n",
       "      <td>b'R2PEOEUR1LP0GH'</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data/customer_id  data/helpful_votes data/marketplace  \\\n",
       "0      b'20980074'                   0            b'US'   \n",
       "1        b'779273'                   0            b'US'   \n",
       "2      b'15410531'                   0            b'US'   \n",
       "3      b'27389005'                   0            b'US'   \n",
       "4       b'2663569'                   0            b'US'   \n",
       "\n",
       "   data/product_category data/product_id data/product_parent  \\\n",
       "0  b'Mobile_Electronics'   b'B00D1847NE'        b'274617424'   \n",
       "1  b'Mobile_Electronics'   b'B00KMO6DYG'        b'397452138'   \n",
       "2  b'Mobile_Electronics'   b'B000GWLL0K'        b'948304826'   \n",
       "3  b'Mobile_Electronics'   b'B008L3JE6Y'        b'466340015'   \n",
       "4  b'Mobile_Electronics'   b'B00GHZS4SC'        b'350592810'   \n",
       "\n",
       "                                  data/product_title  \\\n",
       "0  b'Teenage Mutant Ninja Turtles Boombox CD Play...   \n",
       "1  b'4 Gauge Amp Kit Amplifier Install Wiring Com...   \n",
       "2  b'Travel Wall Charger fits Creative Zen Vision...   \n",
       "3  b'High Grade Robust 360\\xc2\\xb0 Adjustable Car...   \n",
       "4  b'HDE Multifunctional Bluetooth FM Audio Car K...   \n",
       "\n",
       "                                    data/review_body data/review_date  \\\n",
       "0                                   b'Does not work'    b'2015-01-09'   \n",
       "1  b'This is a great wiring kit i used it to set ...    b'2015-08-06'   \n",
       "2  b'It works great so much faster than USB charg...    b'2007-03-15'   \n",
       "3  b'This product was purchased to hold a monitor...    b'2013-07-30'   \n",
       "4  b\"it works but it has really bad sound quality...    b'2014-12-31'   \n",
       "\n",
       "                       data/review_headline     data/review_id  \\\n",
       "0                               b'One Star'  b'R1OVS0D6SEXPW7'   \n",
       "1                              b'Great kit'   b'R9VSD0ET8FERB'   \n",
       "2  b'A/C Charger for Creative Zen Vision M'  b'R3ISXCZHWLJLBH'   \n",
       "3                           b'camera stand'  b'R1TWVUDOFJSQAW'   \n",
       "4                      b'bad sound quality'  b'R2PEOEUR1LP0GH'   \n",
       "\n",
       "   data/star_rating  data/total_votes  data/verified_purchase  data/vine  \n",
       "0                 1                 0                       0          1  \n",
       "1                 4                 0                       0          1  \n",
       "2                 5                 0                       0          1  \n",
       "3                 5                 0                       0          1  \n",
       "4                 3                 0                       0          1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the top records\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data/customer_id</th>\n",
       "      <th>data/helpful_votes</th>\n",
       "      <th>data/marketplace</th>\n",
       "      <th>data/product_category</th>\n",
       "      <th>data/product_id</th>\n",
       "      <th>data/product_parent</th>\n",
       "      <th>data/product_title</th>\n",
       "      <th>data/review_body</th>\n",
       "      <th>data/review_date</th>\n",
       "      <th>data/review_headline</th>\n",
       "      <th>data/review_id</th>\n",
       "      <th>data/star_rating</th>\n",
       "      <th>data/total_votes</th>\n",
       "      <th>data/verified_purchase</th>\n",
       "      <th>data/vine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104970</th>\n",
       "      <td>b'16433874'</td>\n",
       "      <td>0</td>\n",
       "      <td>b'US'</td>\n",
       "      <td>b'Mobile_Electronics'</td>\n",
       "      <td>b'B003SH571E'</td>\n",
       "      <td>b'816208213'</td>\n",
       "      <td>b'BlueAnt S4 Bluetooth Car Speakerphone Kit [U...</td>\n",
       "      <td>b\"It's a wonderful invention. You don't need t...</td>\n",
       "      <td>b'2012-09-17'</td>\n",
       "      <td>b'excellent gadget'</td>\n",
       "      <td>b'RCDFUCZ20BO1Y'</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104971</th>\n",
       "      <td>b'11714515'</td>\n",
       "      <td>3</td>\n",
       "      <td>b'US'</td>\n",
       "      <td>b'Mobile_Electronics'</td>\n",
       "      <td>b'B00HK6CPVY'</td>\n",
       "      <td>b'383636318'</td>\n",
       "      <td>b'Szstudio US 5\" Car GPS Navigation Sat Nav Bu...</td>\n",
       "      <td>b\"This is not good item,I can even maket work,...</td>\n",
       "      <td>b'2014-04-26'</td>\n",
       "      <td>b'Do not waste your money'</td>\n",
       "      <td>b'RU0PWIV6N2OW5'</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104972</th>\n",
       "      <td>b'51380565'</td>\n",
       "      <td>0</td>\n",
       "      <td>b'US'</td>\n",
       "      <td>b'Mobile_Electronics'</td>\n",
       "      <td>b'B005CJ769C'</td>\n",
       "      <td>b'698252499'</td>\n",
       "      <td>b'New Barnes Noble Nook 2 2nd Edition Generati...</td>\n",
       "      <td>b'The cover and skin were both exactly like th...</td>\n",
       "      <td>b'2012-01-16'</td>\n",
       "      <td>b'Great product!'</td>\n",
       "      <td>b'R3R5T9X5WW8C25'</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104973</th>\n",
       "      <td>b'24019237'</td>\n",
       "      <td>0</td>\n",
       "      <td>b'US'</td>\n",
       "      <td>b'Mobile_Electronics'</td>\n",
       "      <td>b'B004911E9M'</td>\n",
       "      <td>b'423996186'</td>\n",
       "      <td>b'Wall AC Charger USB Sync Data Cable for iPho...</td>\n",
       "      <td>b'I ordered 2 of these cords for both mine and...</td>\n",
       "      <td>b'2011-12-13'</td>\n",
       "      <td>b'Horrible. DOES NOT WORK with iPhone 3GS'</td>\n",
       "      <td>b'R300CMC3CKOQRO'</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104974</th>\n",
       "      <td>b'7627794'</td>\n",
       "      <td>0</td>\n",
       "      <td>b'US'</td>\n",
       "      <td>b'Mobile_Electronics'</td>\n",
       "      <td>b'B00ATWD880'</td>\n",
       "      <td>b'866011377'</td>\n",
       "      <td>b'Covert Acoustic Tube Earpiece 2 PIN for ICOM...</td>\n",
       "      <td>b'Item works better than I had hoped for. Very...</td>\n",
       "      <td>b'2013-06-25'</td>\n",
       "      <td>b'Makes wearing an earpiece comfortable'</td>\n",
       "      <td>b'R1KL85UT0HAW24'</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       data/customer_id  data/helpful_votes data/marketplace  \\\n",
       "104970      b'16433874'                   0            b'US'   \n",
       "104971      b'11714515'                   3            b'US'   \n",
       "104972      b'51380565'                   0            b'US'   \n",
       "104973      b'24019237'                   0            b'US'   \n",
       "104974       b'7627794'                   0            b'US'   \n",
       "\n",
       "        data/product_category data/product_id data/product_parent  \\\n",
       "104970  b'Mobile_Electronics'   b'B003SH571E'        b'816208213'   \n",
       "104971  b'Mobile_Electronics'   b'B00HK6CPVY'        b'383636318'   \n",
       "104972  b'Mobile_Electronics'   b'B005CJ769C'        b'698252499'   \n",
       "104973  b'Mobile_Electronics'   b'B004911E9M'        b'423996186'   \n",
       "104974  b'Mobile_Electronics'   b'B00ATWD880'        b'866011377'   \n",
       "\n",
       "                                       data/product_title  \\\n",
       "104970  b'BlueAnt S4 Bluetooth Car Speakerphone Kit [U...   \n",
       "104971  b'Szstudio US 5\" Car GPS Navigation Sat Nav Bu...   \n",
       "104972  b'New Barnes Noble Nook 2 2nd Edition Generati...   \n",
       "104973  b'Wall AC Charger USB Sync Data Cable for iPho...   \n",
       "104974  b'Covert Acoustic Tube Earpiece 2 PIN for ICOM...   \n",
       "\n",
       "                                         data/review_body data/review_date  \\\n",
       "104970  b\"It's a wonderful invention. You don't need t...    b'2012-09-17'   \n",
       "104971  b\"This is not good item,I can even maket work,...    b'2014-04-26'   \n",
       "104972  b'The cover and skin were both exactly like th...    b'2012-01-16'   \n",
       "104973  b'I ordered 2 of these cords for both mine and...    b'2011-12-13'   \n",
       "104974  b'Item works better than I had hoped for. Very...    b'2013-06-25'   \n",
       "\n",
       "                              data/review_headline     data/review_id  \\\n",
       "104970                         b'excellent gadget'   b'RCDFUCZ20BO1Y'   \n",
       "104971                  b'Do not waste your money'   b'RU0PWIV6N2OW5'   \n",
       "104972                           b'Great product!'  b'R3R5T9X5WW8C25'   \n",
       "104973  b'Horrible. DOES NOT WORK with iPhone 3GS'  b'R300CMC3CKOQRO'   \n",
       "104974    b'Makes wearing an earpiece comfortable'  b'R1KL85UT0HAW24'   \n",
       "\n",
       "        data/star_rating  data/total_votes  data/verified_purchase  data/vine  \n",
       "104970                 4                 0                       0          1  \n",
       "104971                 1                 5                       0          1  \n",
       "104972                 5                 0                       0          1  \n",
       "104973                 1                 0                       0          1  \n",
       "104974                 5                 0                       0          1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the bottom details\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104975, 15)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of our dataset\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data/review_body</th>\n",
       "      <th>data/star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'Does not work'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'This is a great wiring kit i used it to set ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'It works great so much faster than USB charg...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'This product was purchased to hold a monitor...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"it works but it has really bad sound quality...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    data/review_body  data/star_rating\n",
       "0                                   b'Does not work'                 1\n",
       "1  b'This is a great wiring kit i used it to set ...                 4\n",
       "2  b'It works great so much faster than USB charg...                 5\n",
       "3  b'This product was purchased to hold a monitor...                 5\n",
       "4  b\"it works but it has really bad sound quality...                 3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Picking the required features that are rating and the review comment\n",
    "\n",
    "df1 = df[['data/review_body', 'data/star_rating']]\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nelly\\AppData\\Local\\Temp\\ipykernel_12268\\158022155.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"Sentiment\"] = df1[\"data/star_rating\"].apply(lambda score: \"positive\" if score >= 3 else \"negative\")\n",
      "C:\\Users\\Nelly\\AppData\\Local\\Temp\\ipykernel_12268\\158022155.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Sentiment'] = df1['Sentiment'].map({'positive':1, 'negative':0})\n",
      "C:\\Users\\Nelly\\AppData\\Local\\Temp\\ipykernel_12268\\158022155.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['short_review'] =df1['data/review_body'].str.decode(\"utf-8\")\n"
     ]
    }
   ],
   "source": [
    "# Converting star rating as either positive or negative\n",
    "### If a positive is greater than or equal to 3 then it's positive, else it's a negative review.\n",
    "df1[\"Sentiment\"] = df1[\"data/star_rating\"].apply(lambda score: \"positive\" if score >= 3 else \"negative\")\n",
    "df1['Sentiment'] = df1['Sentiment'].map({'positive':1, 'negative':0})\n",
    "\n",
    "# Removing the punctuation on on the review statements.\n",
    "df1['short_review'] =df1['data/review_body'].str.decode(\"utf-8\")\n",
    "df1 = df1[[\"short_review\", \"Sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does not work</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a great wiring kit i used it to set up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It works great so much faster than USB charger...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This product was purchased to hold a monitor o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it works but it has really bad sound quality. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        short_review  Sentiment\n",
       "0                                      Does not work          0\n",
       "1  This is a great wiring kit i used it to set up...          1\n",
       "2  It works great so much faster than USB charger...          1\n",
       "3  This product was purchased to hold a monitor o...          1\n",
       "4  it works but it has really bad sound quality. ...          1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of the top records from the cleaned dataset\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    80077\n",
       "0    24898\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of positive and negative comments\n",
    "\n",
    "df1[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nelly\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Removing links \n",
    "df1[\"short_review\"] = df1[\"short_review\"].apply(lambda s: ' '.join(re.sub(\"(w+://S+)\", \" \", s).split()))\n",
    "\n",
    "#Changing all the letter to lower case\n",
    "df1[\"short_review\"] = df1.short_review.map(lambda x: x.lower())\n",
    "\n",
    "#Removing the punctuation\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = set(stopwords.words(\"english\")) \n",
    "df1[\"short_review\"] = df1[\"short_review\"].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))\n",
    "df1[\"short_review\"] = df1[\"short_review\"].str.replace('user','')\n",
    "\n",
    "# Removing emojis\n",
    "def deEmojify(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "df1[\"short_review\"] = df1[\"short_review\"].apply(lambda s: deEmojify(s))\n",
    "\n",
    "# to remove stop words\n",
    "df1[\"short_review\"] = df1[\"short_review\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tokenization**\n",
    "##### We are going to to use word tokenization to convert to convert the reviews to individual word.\n",
    "##### I chose to Lemmatize due to the nature of our analysis, the benefit of lemmetization is that it converts the words into there base formart. \n",
    "##### Runs, Ran, Running are all converted to Run which is prefarable to stemming which leaves thw words in an incomplete state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>work</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great wiring kit used set pyle 2000 watt amp 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>works great much faster usb chargerbuy glad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product purchased hold monitor desk connected ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>works really bad sound quality bass doesnt wor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        short_review  Sentiment\n",
       "0                                               work          0\n",
       "1  great wiring kit used set pyle 2000 watt amp 2...          1\n",
       "2        works great much faster usb chargerbuy glad          1\n",
       "3  product purchased hold monitor desk connected ...          1\n",
       "4  works really bad sound quality bass doesnt wor...          1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nelly\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download the required data files\n",
    "nltk.download('punkt')\n",
    "\n",
    "# After downloading the data files, you can use the word_tokenize function\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# word tokenizing\n",
    "df1[\"short_review\"] = df1[\"short_review\"].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[work]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[great, wire, kit, use, set, pyle, 2000, watt,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[work, great, much, faster, usb, chargerbuy, g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[product, purchase, hold, monitor, desk, conne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[work, really, bad, sound, quality, bass, does...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104970</th>\n",
       "      <td>[wonderful, invention, dont, need, wrap, bluet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104971</th>\n",
       "      <td>[good, itemi, even, maket, workthe, gps, app, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104972</th>\n",
       "      <td>[cover, skin, exactly, like, picture, describe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104973</th>\n",
       "      <td>[order, 2, cord, mine, husband, iphone, 3gs, n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104974</th>\n",
       "      <td>[item, work, better, hop, comfortable, easy, h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             short_review  Sentiment\n",
       "0                                                  [work]          0\n",
       "1       [great, wire, kit, use, set, pyle, 2000, watt,...          1\n",
       "2       [work, great, much, faster, usb, chargerbuy, g...          1\n",
       "3       [product, purchase, hold, monitor, desk, conne...          1\n",
       "4       [work, really, bad, sound, quality, bass, does...          1\n",
       "...                                                   ...        ...\n",
       "104970  [wonderful, invention, dont, need, wrap, bluet...          1\n",
       "104971  [good, itemi, even, maket, workthe, gps, app, ...          0\n",
       "104972  [cover, skin, exactly, like, picture, describe...          1\n",
       "104973  [order, 2, cord, mine, husband, iphone, 3gs, n...          0\n",
       "104974  [item, work, better, hop, comfortable, easy, h...          1\n",
       "\n",
       "[104975 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing the data.\n",
    "\n",
    "#nltk.download('omw-1.4')\n",
    "#nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "\n",
    "df1[\"short_review\"] = df1[\"short_review\"].apply(lambda tokens: [lemmatiser.lemmatize(token, pos='v') for token in tokens])\n",
    "df1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **NAIVE BAYES MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8713\n",
      "Precision: 0.8661\n",
      "Recall: 0.8713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "df1['short_review'] = df1['short_review'].apply(' '.join) \n",
    "# Split the data into train and test sets\n",
    "X = df1['short_review']\n",
    "y = df1['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predict the sentiment labels for test data\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validating using a new review \n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the trained model as a .pkl file\n",
    "with open('naive_bayes_model.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file)\n",
    "\n",
    "# Load the trained Naive Bayes model\n",
    "with open('naive_bayes_model.pkl', 'rb') as file:\n",
    "    naive_model = pickle.load(file)\n",
    "\n",
    "new_review = input(\"Enter a review: \")\n",
    "\n",
    "# Preprocess the new review\n",
    "new_review = new_review.lower()\n",
    "new_review = word_tokenize(new_review)\n",
    "new_review = ' '.join(new_review)\n",
    "\n",
    "# Load the CountVectorizer used during training\n",
    "vectorizer = CountVectorizer()  # Create a new CountVectorizer object\n",
    "vectorizer.fit(X_train)  # Fit it to your training data\n",
    "\n",
    "# Vectorize the new review\n",
    "new_review_vectorized = vectorizer.transform([new_review])\n",
    "\n",
    "# Predict the sentiment label of the new review\n",
    "naive_model.predict(new_review_vectorized)[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SUPPORT VECTOR MACHINE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72      4906\n",
      "           1       0.91      0.93      0.92     16089\n",
      "\n",
      "    accuracy                           0.87     20995\n",
      "   macro avg       0.83      0.81      0.82     20995\n",
      "weighted avg       0.87      0.87      0.87     20995\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nelly\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC \n",
    "model = LinearSVC().fit(X_train_vectorized, y_train)\n",
    "predicted = model.predict(X_test_vectorized)\n",
    "report = classification_report( y_test, predicted )\n",
    "print(report)\n",
    "acc=accuracy_score(y_test,predicted)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **LOGISTIC REGRESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8837818528221005\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.69      0.74      4906\n",
      "           1       0.91      0.94      0.93     16089\n",
      "\n",
      "    accuracy                           0.88     20995\n",
      "   macro avg       0.85      0.82      0.83     20995\n",
      "weighted avg       0.88      0.88      0.88     20995\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nelly\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the logistic regression model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "classification_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{classification_report}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **CONCLUSION AND RECOMMENDATION**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The were higher number of positive comments for the Amazon mobile electronic products.\n",
    "\n",
    "Naive Bayles has the highest accuracy. \n",
    "\n",
    "The data should be increased and the number of negative responses increased to create a larger training for higher accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13b752db4915d6435adba8532810304371dd3218712876c32bff82f3883c1332"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
